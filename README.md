# Supervised_Learning_collection
#  Machine Learning Basics – Projects  

>  A collection of machine learning tasks covering **regression**, **polynomial regression**, **multiple linear regression**, **classification**, **decision trees**, and **data visualization (Matplotlib)**.  
> Each task was implemented and tested using **Python**, leveraging libraries like **Pandas**, **NumPy**, **Scikit-learn**, and **Matplotlib**.

---

##  Overview
This repository contains my first-week projects from the **Machine Learning Fundamentals Track**.  
The tasks focus on building intuition for different supervised learning models and visualizing their performance.

---

##  Topics Covered
-  **Simple Linear Regression** – predicting continuous values using one feature.  
-  **Multiple Linear Regression** – using multiple features for improved accuracy.  
-  **Polynomial Regression** – capturing nonlinear relationships.  
-  **Classification (Binary)** – basic classifiers to predict categorical outcomes.  
-  **Decision Tree Classifier** – rule-based prediction with visual tree interpretation.  
-  **Data Visualization (Matplotlib)** – plotting trends, scatter plots, and regression lines.

---

##  Project Files
| Folder | Description |
|--------|--------------|
| `1_linear_regression/` | Predicting student scores based on study hours. |
| `2_multiple_regression/` | Predicting sales using multiple factors (TV, Radio, Newspaper). |
| `3_polynomial_regression/` | Predicting growth trends with nonlinear patterns. |
| `4_classification_basic/` | Binary classification examples (e.g., Titanic survival, pass/fail). |
| `5_decision_trees/` | Decision Tree implementation and visualization (student, loan, weather datasets). |
| `6_visualization/` | Matplotlib examples: scatter, line, histogram, regression plot. |

---

## Libraries Used
```python
pandas  
numpy  
matplotlib  
scikit-learn
```
## Key Learnings
Understanding X (features) and y (target) separation.

Training and testing models using train_test_split.

Avoiding overfitting with max_depth, random_state, and proper data splitting.

Evaluating model accuracy with r2_score and accuracy_score.

Visualizing patterns to interpret results clearly.

## Next Step
Proceeding to Week 2: Data Cleaning, Feature Engineering & Random Forests 
